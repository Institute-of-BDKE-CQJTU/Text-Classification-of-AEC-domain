model_name,learning_rate,batch_size,weight_decay,num_warmup_steps,epochs,seed,test_f1
roberta,0.0001,64,0.01,0.1,50,2024,0.8913806887340877
roberta,0.0001,64,0.001,0.1,50,2024,0.9055602525774417
roberta,0.0001,128,0.01,0.1,50,2024,0.9121323810764804
roberta,0.0001,128,0.001,0.1,50,2024,0.9050050055280522
roberta,3e-05,64,0.01,0.1,50,2024,0.8981042102538845
roberta,3e-05,64,0.001,0.1,50,2024,0.8981042102538845
roberta,3e-05,128,0.01,0.1,50,2024,0.8850549062107917
roberta,3e-05,128,0.001,0.1,50,2024,0.9119548852341276
roberta,5e-05,64,0.01,0.1,50,2024,0.898616712184424
roberta,5e-05,64,0.001,0.1,50,2024,0.8849626866593993
roberta,5e-05,128,0.01,0.1,50,2024,0.9052026673523416
roberta,5e-05,128,0.001,0.1,50,2024,0.8784684259839539
roberta,7e-05,64,0.01,0.1,50,2024,0.8782008317085808
roberta,7e-05,64,0.001,0.1,50,2024,0.8858196087049227
roberta,7e-05,128,0.01,0.1,50,2024,0.8989436424976496
roberta,7e-05,128,0.001,0.1,50,2024,0.9048275096856994
roberta,9e-05,64,0.01,0.1,50,2024,0.8843427595707231
roberta,9e-05,64,0.001,0.1,50,2024,0.8774923917812769
roberta,9e-05,128,0.01,0.1,50,2024,0.8709485542089631
roberta,9e-05,128,0.001,0.1,50,2024,0.8849253319425211
